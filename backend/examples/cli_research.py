import sys
import os
from pathlib import Path

# ç¡®ä¿ä½¿ç”¨æœ¬åœ°ä»£ç è€Œä¸æ˜¯å·²å®‰è£…çš„åŒ…
current_dir = Path(__file__).parent
src_dir = current_dir.parent / "src"
sys.path.insert(0, str(src_dir))

import argparse
from langchain_core.messages import HumanMessage, AIMessage, AIMessageChunk
from agent.graph import graph


def main() -> None:
    """Run the research agent from the command line."""
    parser = argparse.ArgumentParser(description="Run the LangGraph research agent")
    parser.add_argument(
        "question", 
        nargs='?',  # ä½¿questionå‚æ•°å¯é€‰ï¼Œæ”¯æŒè°ƒè¯•æ¨¡å¼
        default="2024å¹´3æœˆä»½å‘è¡Œäººæœ‰æ¯å€ºåŠ¡æ€»é¢?",  # é»˜è®¤é—®é¢˜ï¼Œä¾¿äºè°ƒè¯•
        help="Research question (default: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ)"
    )
    parser.add_argument(
        "--initial-queries",
        type=int,
        default=3,
        help="Number of initial search queries",
    )
    parser.add_argument(
        "--max-loops",
        type=int,
        default=2,
        help="Maximum number of research loops",
    )
    parser.add_argument(
        "--reasoning-model",
        default="qwen-max",
        help="Model for the final answer",
    )
    parser.add_argument(
        "--stream-mode",
        nargs="+",
        default=["updates", "messages", "custom"],
        choices=["updates", "messages", "custom", "values", "debug"],
        help="Stream modes to use for output (default: updates messages custom)",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug mode with verbose output",
    )
    args = parser.parse_args()
    
    # æ£€æŸ¥å¹¶è®¾ç½®API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®API Key: set DASHSCOPE_API_KEY=your-api-key")
        print("æˆ–è€…åˆ›å»º .env æ–‡ä»¶è®¾ç½®ç¯å¢ƒå˜é‡")
        print("ç»§ç»­ä½¿ç”¨æµ‹è¯•æ¨¡å¼...")
        os.environ["DASHSCOPE_API_KEY"] = "test-key-for-debugging"
    
    # Debugæ¨¡å¼ä¿¡æ¯è¾“å‡º
    if args.debug:
        print("ğŸ› Debugæ¨¡å¼å·²å¯ç”¨")
        print(f"ğŸ“ ç ”ç©¶é—®é¢˜: {args.question}")
        print(f"ğŸ” åˆå§‹æŸ¥è¯¢æ•°: {args.initial_queries}")
        print(f"ğŸ”„ æœ€å¤§å¾ªç¯æ•°: {args.max_loops}")
        print(f"ğŸ¤– æ¨ç†æ¨¡å‹: {args.reasoning_model}")
        print(f"ğŸ“¡ æµå¼æ¨¡å¼: {args.stream_mode}")
        print(f"ğŸ”‘ API Key: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®ï¼ˆä½¿ç”¨æµ‹è¯•æ¨¡å¼ï¼‰'}")
        print("-" * 50)

    state = {
        "messages": [HumanMessage(content=args.question)],
        "initial_search_query_count": args.initial_queries,
        "max_research_loops": args.max_loops,
        "reasoning_model": args.reasoning_model,
    }

    try:
        print(f"ğŸš€ å¼€å§‹ç ”ç©¶é—®é¢˜: {args.question}")
        print(f"ğŸ“¡ ä½¿ç”¨æµå¼æ¨¡å¼: {', '.join(args.stream_mode)}")
        print("-" * 50)
        
        # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ stream_mode
        for chunk in graph.stream(state, stream_mode=args.stream_mode):
            # print(chunk)
            chunk_type, chunk_data = chunk
            if chunk_type == "messages":
                node_data, node_meta = chunk_data
                node_name = node_meta.get("langgraph_node", "unknown_node")
                aimessage: AIMessageChunk = node_data
                # ä¼˜åŒ–è¾“å‡ºï¼šèŠ‚ç‚¹åå’Œå†…å®¹åœ¨ä¸€è¡Œï¼Œå»é™¤å¤šä½™æ¢è¡Œ
                content = aimessage.content.replace("\n", " ").strip()
                # print(f"{content}", end="", flush=True)
            elif chunk_type == "custom":
                print("\n**" + str(chunk_data) + "**\n")
            # elif chunk_type == "updates":
                # è§£æ chunk_dataï¼Œæå– node_name å’Œ node_message
                # for node_name, node_message in chunk_data.items():
                    # print(f"èŠ‚ç‚¹åç§°: {node_name}")
                    # print(f"èŠ‚ç‚¹æ¶ˆæ¯: {node_message}")
            elif chunk_type == "values":
                # æ˜¾ç¤ºå®Œæ•´çŠ¶æ€å€¼
                if args.debug:
                    print(f"ğŸ“Š å½“å‰çŠ¶æ€: {chunk_data}")
            elif chunk_type == "debug":
                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                if args.debug:
                    print(f"ğŸ› è°ƒè¯•ä¿¡æ¯: {chunk_data}")
        print("\n" + "="*50)
        print("\nğŸ“– ç ”ç©¶å®Œæˆ")

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
